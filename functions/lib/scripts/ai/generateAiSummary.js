"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.generateAiSummary = void 0;
// functions/src/scripts/generateAiSummary.ts
require("dotenv/config");
const firebaseAdmin_1 = require("../../lib/firebaseAdmin");
const openai_1 = require("openai");
const logger_1 = require("../../lib/logger");
const configuration = new openai_1.Configuration({
    apiKey: process.env.OPENAI_API_KEY,
});
const openai = new openai_1.OpenAIApi(configuration);
const generateAiSummary = async () => {
    var _a, _b, _c;
    try {
        const startOfToday = new Date();
        startOfToday.setHours(0, 0, 0, 0);
        const snapshot = await firebaseAdmin_1.db
            .collection("monitoredItems")
            .where("updatedAt", ">=", startOfToday.toISOString())
            .get();
        if (snapshot.empty) {
            logger_1.logger.info("ğŸŸ¡ ä»Šæ—¥æ›´æ–°ã•ã‚ŒãŸ monitoredItems ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
            return;
        }
        const batch = firebaseAdmin_1.db.batch();
        let processedCount = 0;
        for (const doc of snapshot.docs) {
            const data = doc.data();
            if (data.aiSummary)
                continue;
            const { displayName, featureHighlights = [], tags = [] } = data;
            const productName = displayName || data.productName || "ã“ã®å•†å“";
            const prompt = `æ¬¡ã®ç‰¹å¾´ã‚’æŒã¤ãƒ¢ãƒã‚¤ãƒ«ãƒãƒƒãƒ†ãƒªãƒ¼ã€Œ${productName}ã€ã«ã¤ã„ã¦ã€ç°¡æ½”ã§ã‚ã‹ã‚Šã‚„ã™ã„é­…åŠ›ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n\nç‰¹å¾´:\n- ${featureHighlights.join("\n- ")}\n\nã‚¿ã‚°: ${tags.join(", ")}\n\nè¦ç´„:`;
            try {
                const completion = await openai.createChatCompletion({
                    model: "gpt-3.5-turbo",
                    messages: [
                        {
                            role: "system",
                            content: "ã‚ãªãŸã¯ECã‚µã‚¤ãƒˆå‘ã‘ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚",
                        },
                        { role: "user", content: prompt },
                    ],
                    temperature: 0.7,
                });
                const aiSummary = (_c = (_b = (_a = completion.data.choices[0].message) === null || _a === void 0 ? void 0 : _a.content) === null || _b === void 0 ? void 0 : _b.trim()) !== null && _c !== void 0 ? _c : "";
                if (!aiSummary) {
                    logger_1.logger.warn(`âš ï¸ è¦ç´„ç”Ÿæˆã«å¤±æ•—ï¼ˆç©ºï¼‰: ${productName}`);
                    continue;
                }
                batch.update(doc.ref, { aiSummary });
                processedCount++;
            }
            catch (err) {
                logger_1.logger.error(`âŒ OpenAIã‚¨ãƒ©ãƒ¼: ${productName}`, err);
                continue; // ã“ã®å•†å“ã ã‘ã‚¹ã‚­ãƒƒãƒ—
            }
        }
        if (processedCount > 0) {
            await batch.commit();
            logger_1.logger.success(`âœ… ${processedCount} ä»¶ã® aiSummary ã‚’ç”Ÿæˆã—ã¦ä¿å­˜ã—ã¾ã—ãŸ`);
        }
        else {
            logger_1.logger.info("ğŸŸ¡ å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆã™ã§ã«å…¨ã¦è¦ç´„æ¸ˆã¿ï¼‰");
        }
    }
    catch (err) {
        logger_1.logger.error("âŒ generateAiSummary å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼:", err);
        throw err;
    }
};
exports.generateAiSummary = generateAiSummary;
// CLI å®Ÿè¡Œç”¨
if (require.main === module) {
    (0, exports.generateAiSummary)().catch(err => {
        logger_1.logger.error("âŒ CLIå®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼:", err);
        process.exit(1);
    });
}
//# sourceMappingURL=generateAiSummary.js.map